{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01cd1d6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data generation: contour extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed508ba",
   "metadata": {},
   "source": [
    "We extract contours of entire songs, phrases and motifs from multiple collections of symbolic music. \n",
    "The original collections should be located in the 'datasets' directory, which is excluded from this repository. The datasets are named by their id in [Catafolk](https://bacor.github.io/catafolk/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f350ecf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from music21 import converter\n",
    "import chant21\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import melodic_contour\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "matplotlib.style.use('styles.mplstyle')\n",
    "\n",
    "import os\n",
    "import glob\n",
    "sys.path.append('../')\n",
    "from helpers import cm2inch, title, show_num_contours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6f3d09",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c44b8f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([61., 58., 58., 61., 61., 61., 58., 61., 58., 56., 57., 56., 56.,\n",
       "        56., 56., 56., 56., 56., 56., 56., 56., 63., 58., 58., 61., 61.,\n",
       "        58., 61., 58., 56., 56., 58., 58., 68., 56., 56., 56., 56., 56.,\n",
       "        56., 56., 61., 58., 58., 61., 61., 61., 58., 58., 56., 56., 56.,\n",
       "        58., 56., 56., 56., 56., 56., 56., 56., 56., 56., 58., 58., 61.,\n",
       "        61., 58., 56., 56., 56., 58., 58., 56., 56., 56., 56., 56., 56.,\n",
       "        56., 56., 58., 58., 61., 61., 58., 56., 56., 56., 58., 58., 56.,\n",
       "        56., 56., 56., 56., 56., 56., 56., 56., 56.]),\n",
       " 61.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_song_contour(filename, num_samples=100):\n",
    "    \"\"\"Extract the contour of a complete song from a kern file\"\"\"\n",
    "    stream = converter.parse(filename)\n",
    "    contour = melodic_contour.stream_to_contour(stream)\n",
    "    pitches = contour.interpolate(num_samples=num_samples).pitches\n",
    "    return pitches, contour.duration\n",
    "\n",
    "extract_song_contour('../datasets/densmore-choctaw/data/choct01.krn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2653ff16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>han0037</th>\n",
       "      <td>16.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>han0751</th>\n",
       "      <td>24.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>han0989</th>\n",
       "      <td>44.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         duration     0     1     2     3     4     5     6     7     8  ...  \\\n",
       "han0037      16.0  79.0  79.0  79.0  79.0  74.0  74.0  74.0  72.0  72.0  ...   \n",
       "han0751      24.0  73.0  73.0  73.0  73.0  73.0  73.0  73.0  71.0  71.0  ...   \n",
       "han0989      44.0  76.0  76.0  76.0  78.0  76.0  73.0  71.0  69.0  66.0  ...   \n",
       "\n",
       "           90    91    92    93    94    95    96    97    98    99  \n",
       "han0037  72.0  72.0  72.0  72.0  72.0  72.0  72.0  72.0  72.0  72.0  \n",
       "han0751  66.0  64.0  64.0  64.0  64.0  64.0  64.0  64.0  64.0  64.0  \n",
       "han0989  71.0  71.0  69.0  66.0  66.0  64.0  64.0  64.0  64.0  64.0  \n",
       "\n",
       "[3 rows x 101 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_song_contours(dataset_dir, max_songs=-1, num_samples=100):\n",
    "    \"\"\"Extract all contours from songs in a (Catafolk) dataset\"\"\"\n",
    "    meta_fn = os.path.join(dataset_dir, 'index.csv')\n",
    "    if os.path.exists(meta_fn):\n",
    "        meta = pd.read_csv(meta_fn, index_col=0)\n",
    "        if 'file_path' in meta.columns:\n",
    "            filenames = meta['file_path'][:max_songs]\n",
    "        else:\n",
    "            filenames = meta['path'][:max_songs]\n",
    "        paths = filenames.map(lambda p: os.path.join(dataset_dir, p))\n",
    "    else:\n",
    "        paths = (glob.glob(f'{dataset_dir}/**/*.krn')\n",
    "                 + glob.glob(f'{dataset_dir}/*.krn')\n",
    "                 + glob.glob(f'{dataset_dir}/**/*.gabc'))[:max_songs]\n",
    "        ids = [os.path.basename(os.path.splitext(p)[0]) for p in paths]\n",
    "        paths = {idx: p for idx, p in zip(ids, paths)}\n",
    "        \n",
    "    contours = []\n",
    "    durations = []\n",
    "    ids = []\n",
    "    for idx, path in paths.items():\n",
    "        try:\n",
    "            contour, duration = extract_song_contour(path, num_samples=num_samples)\n",
    "            ids.append(idx)\n",
    "            durations.append([duration])\n",
    "            contours.append(contour.astype(int))\n",
    "        except:\n",
    "            print(f'Error: could not extract contour from {path}')\n",
    "\n",
    "    df = pd.DataFrame(np.concatenate([durations, contours], axis=1))\n",
    "    df.columns = ['duration'] + list(range(num_samples))\n",
    "    df.index = ids\n",
    "    return df\n",
    "\n",
    "get_song_contours(f'../datasets/han/', max_songs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c712b012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets_dir = '../datasets'\n",
    "datasets = [\n",
    "    'densmore-teton-sioux',\n",
    "    'densmore-menominee',\n",
    "    'densmore-nootka',\n",
    "    'densmore-northern-ute',\n",
    "    'densmore-maidu',\n",
    "    'densmore-pawnee',\n",
    "    'densmore-pueblo',\n",
    "    'densmore-papago',\n",
    "    'densmore-ojibway',\n",
    "    'densmore-choctaw',\n",
    "    'boehme-altdeutsches-liederbuch',\n",
    "    'han',\n",
    "    'shanxi',\n",
    "    'natmin',\n",
    "    'erk',\n",
    "    'gregobase',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f83c66ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skpping densmore-teton-sioux: already exists\n",
      "Skpping densmore-menominee: already exists\n",
      "Skpping densmore-nootka: already exists\n",
      "Skpping densmore-northern-ute: already exists\n",
      "Skpping densmore-maidu: already exists\n",
      "Skpping densmore-pawnee: already exists\n",
      "Skpping densmore-pueblo: already exists\n",
      "Skpping densmore-papago: already exists\n",
      "Skpping densmore-ojibway: already exists\n",
      "Skpping densmore-choctaw: already exists\n",
      "Skpping boehme-altdeutsches-liederbuch: already exists\n",
      "Skpping han: already exists\n",
      "Skpping shanxi: already exists\n",
      "Skpping natmin: already exists\n",
      "Skpping erk: already exists\n",
      "Skpping gregobase: already exists\n"
     ]
    }
   ],
   "source": [
    "refresh = False\n",
    "for dataset in datasets:\n",
    "    output_fn = f'../data/song-contours/{dataset}.csv'\n",
    "    if not os.path.exists(output_fn) or refresh:\n",
    "        print(f'Starting with {dataset}')\n",
    "        df = get_song_contours(\n",
    "            os.path.join(datasets_dir, dataset),\n",
    "            max_songs=-1, num_samples=100)\n",
    "        df.to_csv(output_fn)\n",
    "    else:\n",
    "        print(f'Skpping {dataset}: already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5a549d",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189a3f93",
   "metadata": {},
   "source": [
    "Phrases are extracted using another code base similar to what was used to extract contours in the [DLfM'20 paper](https://github.com/bacor/DLfM2020)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f8f4d2",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Motifs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269552aa",
   "metadata": {},
   "source": [
    "We extract motifs from Gregorian chant. \n",
    "We use the exact same data that was used in our ISMIR2020 paper on mode classification.\n",
    "This data can be downloaded from https://github.com/bacor/ISMIR2020/tree/master/data/run-0; please put it in `../datasets/cornelissen-etal-2020-run0/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "860a5356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_VOLPIANO_TO_MIDI = {\n",
    "    \"8\": 53, # F\n",
    "    \"9\": 55, # G\n",
    "    \"a\": 57,\n",
    "    \"y\": 58, # B flat\n",
    "    \"b\": 59,\n",
    "    \"c\": 60,\n",
    "    \"d\": 62,\n",
    "    \"w\": 63, # E flat\n",
    "    \"e\": 64,\n",
    "    \"f\": 65,\n",
    "    \"g\": 67,\n",
    "    \"h\": 69,\n",
    "    \"i\": 70, # B flat\n",
    "    \"j\": 71,\n",
    "    \"k\": 72, # C\n",
    "    \"l\": 74,\n",
    "    \"x\": 75, # E flat\n",
    "    \"m\": 76,\n",
    "    \"n\": 77,\n",
    "    \"o\": 79,\n",
    "    \"p\": 81,\n",
    "    \"z\": 82, # B flat\n",
    "    \"q\": 83, # B\n",
    "    \"r\": 84, # C\n",
    "    \"s\": 86,\n",
    "    \n",
    "    # Liquescents\n",
    "    \"(\": 53,\n",
    "    \")\": 55,\n",
    "    \"A\": 57,\n",
    "    \"B\": 59,\n",
    "    \"C\": 60,\n",
    "    \"D\": 62,\n",
    "    \"E\": 64,\n",
    "    \"F\": 65,\n",
    "    \"G\": 67,\n",
    "    \"H\": 69,\n",
    "    \"J\": 71,\n",
    "    \"K\": 72, # C\n",
    "    \"L\": 74,\n",
    "    \"M\": 76,\n",
    "    \"N\": 77,\n",
    "    \"O\": 79,\n",
    "    \"P\": 81,\n",
    "    \"Q\": 83,\n",
    "    \"R\": 84, # C\n",
    "    \"S\": 86, # D\n",
    "    \n",
    "    # Naturals\n",
    "    \"Y\": 59, # Natural at B\n",
    "    \"W\": 64, # Natural at E\n",
    "    \"I\": 71, # Natural at B\n",
    "    \"X\": 76, # Natural at E\n",
    "    \"Z\": 83,\n",
    "}\n",
    "\n",
    "def volpiano_to_midi(volpiano, fill_na=False, skip_accidentals=False):\n",
    "    \"\"\"\n",
    "    Translates volpiano pitches to a list of midi pitches\n",
    "\n",
    "    All non-note characters are ignored or filled with `None`, if `fill_na=True`\n",
    "    Unless `skip_accidentals=True`, accidentals are converted to midi pitches\n",
    "    as well. So an i (flat at the B) becomes 70, a B flat. Or a W (a natural at\n",
    "    the E) becomes 64 (E).\n",
    "    \"\"\"\n",
    "    accidentals = 'iwxyz' + 'IWXYZ'\n",
    "    midi = []\n",
    "    for char in volpiano:\n",
    "        if skip_accidentals and char in accidentals:\n",
    "            pass\n",
    "        elif char in _VOLPIANO_TO_MIDI:\n",
    "            midi.append(_VOLPIANO_TO_MIDI[char])\n",
    "        elif fill_na:\n",
    "            midi.append(None)\n",
    "    return midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e80353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def volpiano_to_contour(volpiano, num_samples=100):\n",
    "    pitches = volpiano_to_midi(volpiano + volpiano[-1])\n",
    "    xs = np.linspace(0, 1, len(pitches))\n",
    "    func = scipy.interpolate.interp1d(xs, pitches, kind='previous')\n",
    "    return func(np.linspace(0, 1, num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff0cd6c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_volpiano_contours(df, num_samples=100, normalize=True):\n",
    "    contours = []\n",
    "    motif_nums = []\n",
    "    durations = []\n",
    "    chant_ids = []\n",
    "    \n",
    "    for chant_id, volpiano in df.items():\n",
    "        segments = volpiano.split()\n",
    "        for i, segment in enumerate(segments):\n",
    "            contour = volpiano_to_contour(segment, num_samples=num_samples)\n",
    "            contours.append(contour.astype(int))\n",
    "            chant_ids.append([chant_id])\n",
    "            motif_nums.append([i+1])\n",
    "            durations.append([len(segment)])\n",
    "            \n",
    "    df = pd.DataFrame(\n",
    "        np.concatenate([chant_ids, motif_nums, durations, contours], axis=1))\n",
    "    df.columns = ['chant_id', 'motif_num', 'duration'] + list(range(num_samples))\n",
    "    return df\n",
    "                   \n",
    "# extract_volpiano_contours(pitches['syllables'][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62183f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chants = pd.read_csv('../datasets/cornelissen-etal-2020-run-0/responsory/subset/train-chants.csv', index_col=0)\n",
    "pitches = pd.read_csv('../datasets/cornelissen-etal-2020-run-0/responsory/subset/train-representation-pitch.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c8f123b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists: neumes\n",
      "Already exists: syllables\n",
      "Already exists: words\n"
     ]
    }
   ],
   "source": [
    "for segmentation in ['neumes', 'syllables', 'words']:\n",
    "    output_fn = f'../data/motif-contours/responsory-subset-{segmentation}.csv'\n",
    "    if not os.path.exists(output_fn):\n",
    "        print(f'Working on {segmentation}')\n",
    "        df = extract_volpiano_contours(pitches[segmentation])\n",
    "        df.to_csv(output_fn)\n",
    "    else:\n",
    "        print(f'Already exists: {segmentation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf2a58a",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Random walks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9204876d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Poisson, contour-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e03743df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_contour(lam, num_samples=50, n=10, p=0.5):\n",
    "    length = max(3, np.random.poisson(lam=lam))\n",
    "    contour = [np.random.randint(60,85)]\n",
    "    for i in range(1, length):\n",
    "        step = np.random.binomial(n, p) - n*p\n",
    "        step = min(max(-12, step), 12)\n",
    "        if (contour[i-1] + step > 84) or (contour[i-1] + step < 60):\n",
    "            contour.append(contour[i-1] - step)\n",
    "        else:\n",
    "            contour.append(contour[i-1] + step)\n",
    "            \n",
    "    contour.append(contour[-1])\n",
    "    c = melodic_contour.Contour(contour)\n",
    "    return c.interpolate(num_samples).pitches, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b119b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_phrase_contours(lam, num_contours=5000, num_samples=100):\n",
    "    contours = []\n",
    "    durations = []\n",
    "    for i in range(num_contours):\n",
    "        contour, duration = random_contour(lam, num_samples=num_samples)\n",
    "        contours.append(contour.astype(int))\n",
    "        durations.append([duration])\n",
    "        \n",
    "    df = pd.DataFrame(np.concatenate([durations, contours], axis=1))\n",
    "    df.columns = ['duration'] + list(range(num_samples))\n",
    "    return df\n",
    "\n",
    "# generate_random_phrase_contours(lam_phrases, num_contours=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c786360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "lam_phrases = 12 \n",
    "df = generate_random_phrase_contours(lam_phrases, num_contours=5000)\n",
    "df.to_csv(f'../data/random-contours/random-lam-{lam_phrases}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56210096",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "df = generate_random_phrase_contours(50, num_contours=5000)\n",
    "df.to_csv('../data/random-contours/random-lam-50.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfaa422",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plain random walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c35c5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_random_walk(length=50, max_step=12, num_samples=100):\n",
    "    contour = [np.random.randint(-max_step,max_step+1)]\n",
    "    for i in range(1, length):\n",
    "        step = np.random.randint(-max_step, max_step+1)\n",
    "        contour.append(contour[i-1] + step)\n",
    "        \n",
    "    contour.append(contour[-1])\n",
    "    c = melodic_contour.Contour(contour)\n",
    "    return c.interpolate(num_samples).pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd581219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_walk_contours(num_contours=5000, length=50, **kwargs):\n",
    "    contours = []\n",
    "    for i in range(num_contours):\n",
    "        contour = uniform_random_walk(length=length, **kwargs)\n",
    "        contours.append(contour.astype(int))\n",
    "\n",
    "    durations = np.array([[length] * num_contours]).T\n",
    "    df = pd.DataFrame(contours)\n",
    "    df['duration'] = length\n",
    "    return df\n",
    "\n",
    "# generate_random_walk_contours(num_contours=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5785b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "df = generate_random_walk_contours(num_contours=5000, length=25)\n",
    "df.to_csv(f'../data/random-contours/random-walk-25.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab86573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
